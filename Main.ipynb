{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd03ca4a2588b5537c8ede33be15af14859fc8078d735d9197621e236497c4aa331",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  user import *\n",
    "from  item import *\n",
    "from user_based_Recommendor import *\n",
    "from item_based_Recommendor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 943 users and 1682 items\n",
    "user_item_matrix=np.full((943+1,1682+1),-1) #each row represents a user and each col represents a item, user_item_matrix[i][j]=user i's rating of item j\n",
    "file = open('ml-100k/u.data', 'r')\n",
    "Lines = file.readlines()\n",
    "for line in Lines:\n",
    "    splits=line.strip().split('\\t')\n",
    "    user_id=int(splits[0])\n",
    "    item_id=int(splits[1])\n",
    "    rating=int(splits[2])\n",
    "\n",
    "    user_item_matrix[user_id][item_id]=rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 943 users and 1682 items\n",
    "item_user_matrix=np.full((1682+1,943+1),-1) #each row represents a user and each col represents a item, user_item_matrix[i][j]=user i's rating of item j\n",
    "file = open('ml-100k/u.data', 'r')\n",
    "Lines = file.readlines()\n",
    "for line in Lines:\n",
    "    splits=line.strip().split('\\t')\n",
    "    user_id=int(splits[0])\n",
    "    item_id=int(splits[1])\n",
    "    rating=int(splits[2])\n",
    "\n",
    "    item_user_matrix[item_id][user_id]=rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict={}\n",
    "file = open('ml-100k/u.user', 'r')\n",
    "Lines = file.readlines()\n",
    "for line in Lines:\n",
    "    splits=line.strip().split('|')\n",
    "    user_id=splits[0]\n",
    "\n",
    "    new_user=user(user_id,splits[1],splits[2],splits[3],splits[4])#id,age,gender,occupation,zip_code\n",
    "    user_dict[user_id]=new_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User id =1, age=24, gender=M, occupation=technician, zip code=85711\nNone\n"
     ]
    }
   ],
   "source": [
    "print(user_dict['1'].printUserInfor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict={}\n",
    "file = open('ml-100k/u.item', 'r',encoding=\"ISO-8859-1\")\n",
    "Lines = file.readlines()\n",
    "for line in Lines:\n",
    "    splits=line.strip().split('|')#1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "    movie_id=splits[0]\n",
    "    new_movie=movie(item_id,splits[1],splits[2],splits[3],splits[4],getTypes(line[-38:]))\n",
    "    item_dict[movie_id]=new_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "movie id=203\nmovie title=Toy Story (1995)\nrelease date=01-Jan-1995\nvideo release date=\nIMDB URL=http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\ntype=Animation,Children's,Comedy\nNone\n"
     ]
    }
   ],
   "source": [
    "print(item_dict['1'].printMovieInfor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_based_Model_Test(user_item_matrix,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_size=[3,6,9,12,15]\n",
    "for n in range(neighbor_size):\n",
    "    print(\"n=\"+str(n))\n",
    "    user_based_Model_Test(user_item_matrix,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1683, 944)\n"
     ]
    }
   ],
   "source": [
    "print(item_user_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n=3\n",
      "  0%|          | 0/1682 [00:41<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f0f42cb2ae19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbor_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mitem_based_Model_Test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Graph-Mining/item_based_Recommendor.py\u001b[0m in \u001b[0;36mitem_based_Model_Test\u001b[0;34m(item_user_matrix, neighbor_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_based_CF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbor_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_avg_rating_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mRMSE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRootMeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Graph-Mining/item_based_Recommendor.py\u001b[0m in \u001b[0;36mitem_based_CF\u001b[0;34m(item_user_matrix, neighbor_size, item_id, user_id, item_avg_rating_dict)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mitem_based_CF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbor_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_avg_rating_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0msorted_sim_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_item_Similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mtop_k_neighbor_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_TopK_neighbor_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_sim_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Graph-Mining/item_based_Recommendor.py\u001b[0m in \u001b[0;36mcalculate_item_Similarity\u001b[0;34m(item_user_matrix, user_id, item_id)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mv2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompare_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_user_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neighbor_size=[3,6,9,12,15]\n",
    "for n in neighbor_size:\n",
    "    print(\"n=\"+str(n))\n",
    "    item_based_Model_Test(item_user_matrix,n)"
   ]
  },
  {
   "source": [
    "SVD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF, accuracy,SVDpp\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies_dataset() -> pd.DataFrame:\n",
    "    movie_data_columns = [\n",
    "    'movie_id', 'title', 'release_date', 'video_release_date', 'url',\n",
    "    'unknown', 'Action', 'Adventure', 'Animation', \"Children's\",\n",
    "    'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "    'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller',\n",
    "    'War', 'Western'\n",
    "    ]\n",
    "\n",
    "    movie_data = pd.read_csv(\n",
    "        'datasets/ml-100k/u.item', \n",
    "        sep = '|', \n",
    "        encoding = \"ISO-8859-1\", \n",
    "        header = None, \n",
    "        names = movie_data_columns,\n",
    "        index_col = 'movie_id'\n",
    "    )\n",
    "    movie_data['release_date'] = pd.to_datetime(movie_data['release_date'])\n",
    "    return movie_data\n",
    "\n",
    "def load_ratings() -> pd.DataFrame:\n",
    "    ratings_data = pd.read_csv(\n",
    "        'ml-100k/u.data',\n",
    "        sep = '\\t',\n",
    "        encoding = \"ISO-8859-1\",\n",
    "        header = None,\n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "    )\n",
    "    \n",
    "    return ratings_data[['user_id', 'movie_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1\n",
       "5      298       474       4\n",
       "6      115       265       2\n",
       "7      253       465       5\n",
       "8      305       451       3\n",
       "9        6        86       3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>298</td>\n      <td>474</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>115</td>\n      <td>265</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>253</td>\n      <td>465</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>305</td>\n      <td>451</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6</td>\n      <td>86</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "ratings_data = load_ratings()\n",
    "ratings_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f=20\n",
      "RMSE: 0.9383\n",
      "f=40\n",
      "RMSE: 0.9405\n",
      "f=60\n",
      "RMSE: 0.9410\n",
      "f=80\n",
      "RMSE: 0.9449\n",
      "f=100\n",
      "RMSE: 0.9474\n"
     ]
    }
   ],
   "source": [
    "min_rating, max_rating = ratings_data['rating'].min(), ratings_data['rating'].max()\n",
    "\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(ratings_data, reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "n_factors=[20,40,60,80,100]\n",
    "for f in n_factors:\n",
    "    print(\"f=\"+str(f))\n",
    "    model = SVD(n_factors=f, biased=False)\n",
    "    model.fit(trainset)\n",
    "\n",
    "    # Let's calculate the RMSE\n",
    "    predictions = model.test(testset)\n",
    "    accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user: 916        item: 642        r_ui = 3.00   est = 3.94   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 0.9287\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9286967871115341"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "n_factors=[20,40,60,80,100]\n",
    "for f in n_factors:\n",
    "    model = SVDpp(n_factors=100)\n",
    "    model.fit(trainset)\n",
    "\n",
    "    predictions = model.test(testset)\n",
    "    accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}